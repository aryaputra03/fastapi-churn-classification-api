name: ML CI/CD Pipeline with FastAPI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      run_training:
        description: 'Run Model Training'
        required: false
        default: "true"
      deploy_api:
        description: "Deploy API after successful build"
        required: false
        default: "false"

env:
  DOCKER_IMAGE: ${{ secrets.DOCKER_IMAGE }}/churn-classifier
  PYTHON_VERSION: '3.10'
  NODE_ENV: production

jobs:
  # ==========================================
  # Job 1: Code Quality & Linting
  # ==========================================
  lint:
    name: Code Quality Check
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Set up python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-lint-${{ hashFiles('requirements-dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-lint-
            ${{ runner.os }}-pip-
      
      - name: Install linting tools
        run: |
          python -m pip install --upgrade pip
          pip install ruff black flake8
      
      - name: Run ruff
        run: |
          ruff check src/ tests/ --output-format=github
        continue-on-error: false
      
      - name: Run Black 
        run: |
          black --check src/ tests/ --line-length=100
        continue-on-error: true
      
      - name: Run flake8
        run: |
          flake8 src/ tests/ --max-line-length=100 --statistics
        continue-on-error: true

  # ==========================================
  # Job 2: Unit Testing
  # ==========================================
  test: 
    name: Unit test
    runs-on: ubuntu-latest
    needs: lint

    strategy:
      matrix: 
        python-version: [ '3.10', '3.11' ]
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Set up python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('requirements-dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
      
      - name: Generate sample data for tests
        run: |
          python -c "from src.utils import setup_directories, generate_sample_data; setup_directories(); generate_sample_data('data/raw/churn_data.csv', n_samples=500)"
      
      - name: Run pytest with coverage
        run: |
          pytest tests/ -v \
            --cov=src \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-report=html
      
      - name: Upload coverage to codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittest
          name: codecov-${{ matrix.python-version }}
          fail_ci_if_error: false
      
      - name: Upload coverage HTML
        uses: actions/upload-artifact@v4
        if: matrix.python-version == '3.10'
        with:
          name: coverage-html
          path: htmlcov/
  
  # ==========================================
  # Job 3: API Tests
  # ==========================================
  test-api:
    name: API Integration Test
    runs-on: ubuntu-latest
    needs: test

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
        
      - name: Generate sample data and train model
        run: |
          python -c "from src.utils import setup_directories, generate_sample_data; setup_directories(); generate_sample_data('data/raw/churn_data.csv', n_samples=500)"
          python -m src.preprocess
          python -m src.train
          python -c "from src.save_preprocessor import create_and_save_preprocessor; create_and_save_preprocessor()"

      - name: Initialize database
        run: |
          python -c "from src.api.database import Base, engine; Base.metadata.create_all(bind=engine); print('Database Initialized')"
      
      - name: Debug - Test prediction locally
        run: |
          python test_prediction_debug.py
      
      - name: Run API tests
        run: |
          pytest tests/test_api.py -v --cov=src.api
      
      - name: Start API Server (Background)
        run: |
          uvicorn src.api.main:app --host 0.0.0.0 --port 8000 &
          sleep 10
      
      - name: Test API Endpoint
        run: |
          curl -f http://localhost:8000/health || exit 1
          
          curl -f http://localhost:8000/model/info || exit 1
          
          curl -f -X POST http://localhost:8000/predict \
            -H "Content-Type: application/json" \
            -d '{
              "customer_id": "C12345",
              "gender": "Male",
              "tenure": 24,
              "monthly_charges": 75.5,
              "total_charges": 1810.0,
              "contract": "One year",
              "payment_method": "Bank transfer (automatic)",
              "internet_service": "Fiber optic"
            }' || exit 1
          echo "All API endpoints working"


  # ==========================================
  # Job 4: DVC Pipeline (Inside Container)
  # ==========================================
  dvc-pipeline-inside-container:
    name: DVC Pipeline (Inside Container)
    runs-on: ubuntu-latest
    needs: [test, test-api]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install DVC
        run: |
          pip install dvc[s3]
      
      - name: Configure DVC remote (if using S3)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          if [ -n "$AWS_ACCESS_KEY_ID" ]; then
            dvc remote modify myremote access_key_id $AWS_ACCESS_KEY_ID
            dvc remote modify myremote secret_access_key $AWS_SECRET_ACCESS_KEY
            echo "DVC remote configured with AWS credentials"
          else
            echo "AWS credentials not found, skipping DVC remote configuration"
          fi

      - name: Pull DVC data
        run: |
          dvc pull || echo "No remote data to pull"
        continue-on-error: true

      - name: Build Docker Image 
        run: |
          docker build -t ml-pipeline:latest -f docker/Dockerfile .
      
      - name: Run DVC pipeline in container 
        run: |
          docker run --rm \
            -v $(pwd)/data:/app/data \
            -v $(pwd)/models:/app/models \
            -v $(pwd)/params.yml:/app/params.yml \
            -v $(pwd)/metrics:/app/metrics \
            -w /app \
            ml-pipeline:latest \
            bash -c "
              python -c 'from src.utils import setup_directories, generate_sample_data; setup_directories(); generate_sample_data(\"data/raw/churn_data.csv\", n_samples=1000)' &&
              python -m src.preprocess &&
              python -m src.train &&
              python -c 'from src.save_preprocessor import create_and_save_preprocessor; create_and_save_preprocessor()' &&
              python -m src.evaluate
              "
    
      - name: Display metrics
        run: |
          if [ -f metrics/metrics.json ]; then
            echo "Model metrics:"
            cat metrics/metrics.json | python -m json.tool
          fi
      
      - name: Push DVC data
        run: |
          dvc push || echo "Could not push to remote"
        continue-on-error: true
      
      - name: Upload pipeline artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-outputs
          path: |
            models/*.pkl
            metrics/metrics.json
            plots/
          retention-days: 30
  
  # ==========================================
  # Job 5: Docker Build & Push (ML Model)
  # ==========================================
  docker-build:
    name: Build & Push Docker Image
    runs-on: ubuntu-latest
    needs: [test, test-api]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        run: |
          if [ -n "$DOCKER_USERNAME" ] && [ -n "$DOCKER_PASSWORD" ]; then
            echo "$DOCKER_PASSWORD" | docker login -u "$DOCKER_USERNAME" --password-stdin
            echo "Successfully logged in to Docker Hub"
          else
            echo "Docker credentials not found, skipping login"
          fi
      
      - name: Extract Metadata
        id: meta 
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKER_IMAGE }}
          tags: |
            type=ref,event=branch
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
      
      - name: Check if Docker push is enabled
        id: check_docker
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
        run: |
          if [ -n "$DOCKER_USERNAME" ]; then
            echo "push_enabled=true" >> $GITHUB_OUTPUT
          else
            echo "push_enabled=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Build Production Image (no push)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile
          push: false
          tags: local/your-app:latest
      
      - name: Build Development Image (no push)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.dev
          push: false
          tags: local/your-app:dev
      
      - name: Image digest
        run: echo ${{ steps.meta.outputs.digest }}

  # ==========================================
  # Job 6: Docker Build & Push (FastAPI)
  # ==========================================
  docker-build-api:
    name: Build FastAPI Docker Image
    runs-on: ubuntu-latest
    needs: [test, test-api]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop')
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: Build and Push API Image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.api
          push: ${{ secrets.DOCKER_USERNAME != '' }}
          tags: |
            ${{ env.DOCKER_IMAGE }}:api
            ${{ env.DOCKER_IMAGE }}:api-${{ github.sha }}
          cache-from: type=registry, ref=${{ env.DOCKER_IMAGE }}:api-buildcache
          cache-to: type=registry, ref=${{ env.DOCKER_IMAGE }}:api-buildcache, mode=max
  
  # ==========================================
  # Job 7: Integration Test
  # ==========================================
  integration-test:
    name: Integration Test 
    runs-on: ubuntu-latest
    needs: [docker-build, docker-build-api]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'

    steps:
      - name: Checkout code 
        uses: actions/checkout@v4
      
      - name: Login to docker hub 
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        run: |
          if [ -n "$DOCKER_USERNAME" ] && [ -n "$DOCKER_PASSWORD" ]; then
            echo "$DOCKER_PASSWORD" | docker login -u "$DOCKER_USERNAME" --password-stdin
            echo "Successfully logged in to Docker Hub"
          else
            echo "Docker credentials not found, will build image locally"
          fi

      - name: Setup directory structure
        run: |
          mkdir -p data/raw data/processed models metrics plots
          rm -rf metrics/metrics.json 2>/dev/null || true
          echo "Directory structure prepared"
      
      - name: Pull latest image 
        run: |
          docker pull ${{ env.DOCKER_IMAGE }}:latest || docker build -t ${{ env.DOCKER_IMAGE }}:latest -f docker/Dockerfile .

      - name: Test preprocessing
        run: |
          docker run --rm \
            -v $(pwd)/data:/app/data \
            -v $(pwd)/params.yml:/app/params.yml \
            ${{ env.DOCKER_IMAGE }}:latest \
            bash -c "python -c 'from src.utils import setup_directories, generate_sample_data; setup_directories(); generate_sample_data(\"data/raw/churn_data.csv\", n_samples=100)' && python -m src.preprocess"
      
      - name: Test Training
        run: |
          docker run --rm \
            -v $(pwd)/data:/app/data \
            -v $(pwd)/models:/app/models \
            -v $(pwd)/params.yml:/app/params.yml \
            ${{ env.DOCKER_IMAGE }}:latest \
            bash -c "python -m src.train && python -c 'from src.save_preprocessor import create_and_save_preprocessor; create_and_save_preprocessor()'"
      
      - name: Test evaluation
        run: |
          docker run --rm \
            -v $(pwd)/data:/app/data \
            -v $(pwd)/models:/app/models \
            -v $(pwd)/params.yml:/app/params.yml \
            -v $(pwd)/metrics:/app/metrics \
            ${{ env.DOCKER_IMAGE }}:latest \
            python -m src.evaluate
      
      - name: Verify outputs
        run: |
          if [ -f models/churn_model.pkl ]; then
            echo "Model file created successfully"
          else
            echo "Model file not found"
            exit 1
          fi

          if [ -f metrics/metrics.json ]; then
            echo "Metrics file created successfully"
            cat metrics/metrics.json
          else  
            echo "Metrics file not found"
            exit 1
          fi
      
      - name: Pull API image
        run: |
          docker pull ${{ env.DOCKER_IMAGE }}:api || docker build -t ${{ env.DOCKER_IMAGE }}:api -f docker/Dockerfile.api .
      
      - name: Test API Container 
        run: |
          docker run -d \
            --name test-api \
            -p 8000:8000 \
            -v $(pwd)/models:/app/models \
            -v $(pwd)/params.yml:/app/params.yml \
            ${{ env.DOCKER_IMAGE }}:api

            echo "Waiting for API to Start..."
            sleep 15

            curl -f http://localhost:8000/health || exit 1
            echo "Health check passed"

            curl -f -X POST http://localhost:8000/predict \
              -H "Content-Type: application/json" \
              -d '{
              "customer_id": "TEST001",
              "gender": "Male",
              "tenure": 24,
              "monthly_charges": 75.5,
              "total_charges": 1810.0,
              "contract": "One year",
              "payment_method": "Bank transfer (automatic)",
              "internet_service": "Fiber optic"
              }' || exit 1
            echo "Prediction endpoint passed"

            docker stop test-api
            docker rm test-api

  # ==========================================
  # Job 8: Notification & Status
  # ==========================================
  notify:
    name: Notifications
    runs-on: ubuntu-latest
    needs: [lint, test, test-api, integration-test]
    if: always()
    
    steps:
      - name: Check pipeline status
        run: |
          echo "========================================="
          echo "CI/CD Pipeline Status"
          echo "========================================="
          echo "Lint:             ${{ needs.lint.result }}"
          echo "Test:             ${{ needs.test.result }}"
          echo "API Test:         ${{ needs.test-api.result }}"
          echo "Integration Test: ${{ needs.integration-test.result }}"
          echo "========================================="
          
          if [[ "${{ needs.lint.result }}" == "failure" || \
                "${{ needs.test.result }}" == "failure" || \
                "${{ needs.test-api.result }}" == "failure" ]]; then
            echo "CI Pipeline Failed"
            exit 1
          elif [[ "${{ needs.integration-test.result }}" == "failure" ]]; then
            echo "CD Pipeline Failed"
            exit 1
          else
            echo "CI/CD Pipeline Passed"
          fi
      
      - name: Create GitHub issue on failure
        if: failure() && github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: 'CI/CD Pipeline Failed',
              body: `Pipeline failed for commit ${context.sha}\n\nWorkflow: ${context.workflow}\nRun: ${context.runId}`,
              labels: ['ci-cd', 'bug']
            })       

